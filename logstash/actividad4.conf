input {
  file {
    path => "C:/ELK/logs/logins2020-06-29T18_22_43.000Z.csv"
    start_position => "beginning"
    sincedb_path => "NUL"
    codec => plain {
      charset => "ISO-8859-1"
    }
  }
}

filter {
  csv {
    separator => ","
    columns => [
      "name",
      "actor.callerType",
      "actor.email",
      "actor.key",
      "actor.profileId",
      "affected_email_address",
      "id.applicationName",
      "id.customerId",
      "id.time",
      "id.uniqueQualifier",
      "ipAddress",
      "is_second_factor",
      "is_suspicious",
      "login_challenge_method",
      "login_challenge_status",
      "login_type",
      "type"
    ]
    skip_empty_columns => true
  }

  #parsear la fecha del campo id.time
  date {
    match => ["id.time", "ISO8601"]
    target => "@timestamp"
    tag_on_failure => ["_dateparsefailure"]
  }

  # Verificar si el campo is_second_factor es true/false y convertirlo a booleano
  mutate {
    convert => {
      "is_second_factor" => "boolean"
      "is_suspicious" => "boolean"
    }
  }

  # Si es necesario, podemos agregar otros filtros aqui, como geoip para IPs o limpieza de campos
  if [ipAddress] {
    geoip {
      source => "ipAddress"
      target => "geoip"
      add_tag => [ "geoip" ]
    }
  }

  mutate {
    #elimina campos vacios o inesesarios
    remove_field => ["message"]
  }
}

#salida de logstash
output {
  elasticsearch {
    hosts => ["http://localhost:9200"]
    user => "elastic"
    password => "123456"
    index => "ejemplo4-%{+YYYY.MM.dd}"  
  }
  #salida de logstash para depuracion 
  stdout {
    codec => rubydebug
  }
}
