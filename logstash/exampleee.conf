input {
  beats {
    port => 5044
  }
}

filter {
  # Extraer campos del log con grok
  grok {
    match => {
      "message" => "%{LOGLEVEL:log_level} %{TIMESTAMP_ISO8601:timestamp} \[%{WORD:thread}\] %{JAVACLASS:class} - %{WORD:category}\|%{NUMBER:execution_time:float}\|%{WORD:action}\|%{WORD:result}\|%{WORD:user}"
    }
  }

  # Parsear la fecha y hora del campo timestamp
  date {
    match => ["timestamp", "ISO8601"]
    target => "@timestamp"  # Usar el campo estandar @timestamp para Kibana
  }

  # Añadir etiquetas adicionales basadas en condiciones
  if [execution_time] > 5.0 {
    mutate {
      add_tag => ["long_execution"]  # Añadir etiqueta si el tiempo de ejecuci9on es mayor a 5 segundos
    }
  }

  if [result] == "SUCCESS" {
    mutate {
      add_tag => ["successful"]  # Etiqueta para acciones exitosas
    }
  } else {
    mutate {
      add_tag => ["failed"]  # Etiqueta para acciones fallidas
    }
  }

  # Convertir el tiempo de ejecucion en un float si es necesario
  mutate {
    convert => { "execution_time" => "float" }
  }

  # Opcipn para descartar logs que no coincidan con el patron grok
  if "_grokparsefailure" in [tags] {
    drop { }
  }
}

output {
  #Envia los datos procesados a Elasticsearch
  elasticsearch {
    hosts => ["http://localhost:9200"]
    index => "loggenerator-%{+YYYY.MM.dd}"  # Índice diario en Elasticsearch
  }

  # Opcion para depuración (descomentar en caso de necesitar debug)
  # stdout { codec => rubydebug }
}
